{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8cf9ae99",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7891ed0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"spam.csv\", encoding=\"ISO-8859-1\")\n",
    "data = data[['v1','v2']]\n",
    "data.columns = ['label','text']\n",
    "\n",
    "data.head()\n",
    "# data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f396e59",
   "metadata": {},
   "source": [
    "### Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9f0efe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n",
    "# no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936a3e9",
   "metadata": {},
   "source": [
    "### Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b18e935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['label'] = data['label'].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40a6f5d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a409afd2",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4bd1070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.2\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "print(nltk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74fa214a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\salah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\salah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\salah\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk, string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "ps = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce4568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['clean_text'] = data['text'].apply(text_cleaning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17502871",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00aad87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X = data['clean_text']\n",
    "y = data['label']\n",
    "\n",
    "cv = CountVectorizer(max_features=5000)\n",
    "X_vec = cv.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf39623",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b7444f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_vec, y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09b1f7",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34597c5b",
   "metadata": {},
   "source": [
    "## Training Different Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045923d",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39c7a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred_lr = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2535a815",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbda3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ab2ec",
   "metadata": {},
   "source": [
    "### Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0b7b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b0d7b2",
   "metadata": {},
   "source": [
    "### Naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "04316173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "y_pred_nb = nb.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410993c3",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "72db4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "# Naive bayes\n",
    "acc_nb = accuracy_score(y_test,y_pred_nb)\n",
    "pre_nb = precision_score(y_test,y_pred_nb)\n",
    "rec_nb = recall_score(y_test,y_pred_nb)\n",
    "f1_nb = f1_score(y_test,y_pred_nb)\n",
    "\n",
    "# Logistic Regression\n",
    "acc_lr = accuracy_score(y_test,y_pred_lr)\n",
    "pre_lr = precision_score(y_test,y_pred_lr)\n",
    "rec_lr = recall_score(y_test,y_pred_lr)\n",
    "f1_lr = f1_score(y_test,y_pred_lr)\n",
    "\n",
    "# Random Forest\n",
    "acc_rf = accuracy_score(y_test,y_pred_rf)\n",
    "pre_rf = precision_score(y_test,y_pred_rf)\n",
    "rec_rf = recall_score(y_test,y_pred_rf)\n",
    "f1_rf = f1_score(y_test,y_pred_rf)\n",
    "\n",
    "#Xgboost\n",
    "acc_xgb = accuracy_score(y_test,y_pred_xgb)\n",
    "pre_xgb = precision_score(y_test,y_pred_xgb)\n",
    "rec_xgb = recall_score(y_test,y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test,y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "caa8ae3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.977578</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.915254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.916968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.979372</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.916968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.973094</td>\n",
       "      <td>0.983871</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.890511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1-score\n",
       "0          Naive Bayes  0.977578   0.931034  0.900000  0.915254\n",
       "1  Logistic Regression  0.979372   1.000000  0.846667  0.916968\n",
       "2        Random Forest  0.979372   1.000000  0.846667  0.916968\n",
       "3              XGBoost  0.973094   0.983871  0.813333  0.890511"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"Model\": [\"Naive Bayes\", \"Logistic Regression\", \"Random Forest\", \"XGBoost\"],\n",
    "    \"Accuracy\": [acc_nb, acc_lr, acc_rf, acc_xgb],\n",
    "    \"Precision\": [pre_nb, pre_lr, pre_rf, pre_xgb],\n",
    "    \"Recall\": [rec_nb, rec_lr, rec_rf, rec_xgb],\n",
    "    \"F1-score\": [f1_nb, f1_lr, f1_rf, f1_xgb]\n",
    "})\n",
    "\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbe7c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = lr  \n",
    "\n",
    "import pickle\n",
    "\n",
    "with open(\"model.pkl\",\"wb\") as f:\n",
    "    pickle.dump(final_model,f)\n",
    "\n",
    "with open(\"vectorizer.pkl\",\"wb\") as f:\n",
    "    pickle.dump(cv,f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ed18a",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4221bbb8",
   "metadata": {},
   "source": [
    "### Why this model was chosen\n",
    "I trained multiple models like Naive Bayes, Logistic Regression, Random Forest, and XGBoost. Among them, Logistic Regression and Random Forest performed the best, especially in terms of F1-score, which balances both precision and recall. Since spam detection needs to avoid both false alarms and missed spam, these models were the most reliable.I chose Logistic Regression to do Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b6f1b",
   "metadata": {},
   "source": [
    "### How features impact prediction\n",
    "Before training, all messages were cleaned and converted into numbers using CountVectorizer.CountVectorizer works by turning each message into a vector based on the frequency of words, so the machine learning model can understand text in numerical form. This helped the model learn from important words in the messages. For example, words like “win” and “claim” likely to appear in spam, while normal conversation words usually indicate real and genuine messages. The model uses these patterns to decide whether a message is spam or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bd5921",
   "metadata": {},
   "source": [
    "### What improvements can be done\n",
    "This system can be improved by using TF-IDF instead of simple word counts to give more importance to meaningful words. The model performance can also be increased by tuning hyperparameters using techniques like cross-validation and grid search. In the future, more advanced approaches such as deep learning models (LSTM or Transformers) can be used to better understand the context of messages and further improve accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
